{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Udemy Sumarizacao com similaridade do cosseno.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNjFr5gORkMyFiNGH6dVBTR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/htsnet/sumarizacao-textos-processamento-linguagem-natural/blob/main/Udemy_Sumarizacao_com_similaridade_do_cosseno.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPTL25Z5ey7S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00imW1o4ghmi"
      },
      "source": [
        "# Sumarização com similaridade do cosseno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyOI8AA1gnLw"
      },
      "source": [
        "# Preparação do texto de exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbpIw6AxgraP"
      },
      "source": [
        "import re\r\n",
        "import nltk\r\n",
        "import string\r\n",
        "from nltk.cluster.util import cosine_distance\r\n",
        "import networkx as nx\r\n",
        "import numpy as np\r\n",
        "from IPython.core.display import HTML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKF9mACugxIf",
        "outputId": "935152fb-3444-48ad-92da-e292b809f538"
      },
      "source": [
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF3XwMWGg66w",
        "outputId": "154bc5c0-0904-403a-c19c-3de222dbcf4f"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('portuguese')\r\n",
        "print(stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZR7XWt7ir7_"
      },
      "source": [
        "def preprocessamento(texto):\r\n",
        "  texto_formatado = texto.lower()\r\n",
        "  tokens = []\r\n",
        "  for token in nltk.word_tokenize(texto_formatado):\r\n",
        "    tokens.append(token)\r\n",
        "\r\n",
        "  tokens = [palavra for palavra in tokens if palavra not in stopwords and palavra not in string.punctuation]\r\n",
        "  texto_formatado = ' '.join([str(elemento) for elemento in tokens if not elemento.isdigit()])\r\n",
        "\r\n",
        "  return texto_formatado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "DEjoIsDO7ra0",
        "outputId": "f7815816-73b8-4455-a82f-f9ec4e9bc5c7"
      },
      "source": [
        "texto_original = \"\"\"\r\n",
        "        A inteligência artificial é a inteligência similar à humana máquinas. Definem como\r\n",
        "        o estudo de agente artificial com inteligência. Ciência e engenharia de\r\n",
        "        produzir máquinas com inteligência. Resolver problemas e possuir\r\n",
        "        inteligência. Relacionada ao comportamento inteligente. Construção de\r\n",
        "        máquinas para raciocinar. Aprender com os erros e acertos. Inteligência\r\n",
        "        artificial é raciocinar nas situações do cotidiano.\r\n",
        "\"\"\"\r\n",
        "texto_original = re.sub(r'\\s+', ' ', texto_original)\r\n",
        "texto_original"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' A inteligência artificial é a inteligência similar à humana máquinas. Definem como o estudo de agente artificial com inteligência. Ciência e engenharia de produzir máquinas com inteligência. Resolver problemas e possuir inteligência. Relacionada ao comportamento inteligente. Construção de máquinas para raciocinar. Aprender com os erros e acertos. Inteligência artificial é raciocinar nas situações do cotidiano. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gfhlZyB77-i"
      },
      "source": [
        "Ver links no jupyter da aula (wikipedia e passo a passo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7rgSVZ38JcF"
      },
      "source": [
        "# Função para calcular a similaridade entre as sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVGjbWWd809K"
      },
      "source": [
        "sentencas_originais = [sentenca for sentenca in nltk.sent_tokenize(texto_original)]\r\n",
        "sentencas_formatadas = [preprocessamento(sentenca_original) for sentenca_original in sentencas_originais]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YX3p7Gp9p1r",
        "outputId": "a4a798c4-31c8-469a-a6bb-24f5394c0256"
      },
      "source": [
        "sentencas_originais"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' A inteligência artificial é a inteligência similar à humana máquinas.',\n",
              " 'Definem como o estudo de agente artificial com inteligência.',\n",
              " 'Ciência e engenharia de produzir máquinas com inteligência.',\n",
              " 'Resolver problemas e possuir inteligência.',\n",
              " 'Relacionada ao comportamento inteligente.',\n",
              " 'Construção de máquinas para raciocinar.',\n",
              " 'Aprender com os erros e acertos.',\n",
              " 'Inteligência artificial é raciocinar nas situações do cotidiano.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rgwYvl89s-D",
        "outputId": "a635a800-20cc-4648-caf1-79c39b9ba1ce"
      },
      "source": [
        "sentencas_formatadas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['inteligência artificial inteligência similar humana máquinas',\n",
              " 'definem estudo agente artificial inteligência',\n",
              " 'ciência engenharia produzir máquinas inteligência',\n",
              " 'resolver problemas possuir inteligência',\n",
              " 'relacionada comportamento inteligente',\n",
              " 'construção máquinas raciocinar',\n",
              " 'aprender erros acertos',\n",
              " 'inteligência artificial raciocinar situações cotidiano']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPcrpNRl-0ny"
      },
      "source": [
        "def calcula_similaridade_sentencas(sentenca1, sentenca2):\r\n",
        "  palavras1 = [palavra for palavra in nltk.word_tokenize(sentenca1)]\r\n",
        "  palavras2 = [palavra for palavra in nltk.word_tokenize(sentenca2)]\r\n",
        "  #print(palavras1)\r\n",
        "  #print(palavras2)\r\n",
        "\r\n",
        "  todas_palavras = list(set(palavras1 + palavras2)) # o set evita que as palavras fiquem duplicadas\r\n",
        "  #print(todas_palavras)\r\n",
        "\r\n",
        "  vetor1 = [0] * len(todas_palavras)\r\n",
        "  vetor2 = [0] * len(todas_palavras)\r\n",
        "  #print(vetor1)\r\n",
        "  #print(vetor2)\r\n",
        "\r\n",
        "  for palavra in palavras1:\r\n",
        "    vetor1[todas_palavras.index(palavra)] += 1\r\n",
        "  for palavra in palavras2:\r\n",
        "    vetor2[todas_palavras.index(palavra)] += 1    \r\n",
        "\r\n",
        "  #print(vetor1)\r\n",
        "  #print(vetor2)  \r\n",
        "\r\n",
        "  return 1 - cosine_distance(vetor1, vetor2) # quanto menor o número maior é a similaridade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyAMFKzRBkwy",
        "outputId": "b81d03e2-0a7d-491c-fa01-6063fd8cfa65"
      },
      "source": [
        "calcula_similaridade_sentencas(sentencas_formatadas[0], sentencas_formatadas[1]) # o resultado aqui é em % ==> 0.47 = 47%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4743416490252569"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLydt7cnFBDV"
      },
      "source": [
        "# Função para gerar matriz de similaridade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M72o2VyaFOxI"
      },
      "source": [
        "def calcula_matriz_similaridade(sentencas):\r\n",
        "  matriz_similaridade = np.zeros((len(sentencas), len(sentencas)))\r\n",
        "  #print(matriz_similaridade)\r\n",
        "  for i in range(len(sentencas)):\r\n",
        "    for j in range(len(sentencas)):\r\n",
        "      if i == j:\r\n",
        "        continue\r\n",
        "      matriz_similaridade[i][j] = calcula_similaridade_sentencas(sentencas[i], sentencas[j])\r\n",
        "\r\n",
        "  return matriz_similaridade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj7IThShFrdY",
        "outputId": "309d0fa1-b7c6-4fd3-c640-89f2fc58e474"
      },
      "source": [
        "calcula_matriz_similaridade(sentencas_formatadas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.47434165, 0.47434165, 0.35355339, 0.        ,\n",
              "        0.20412415, 0.        , 0.47434165],\n",
              "       [0.47434165, 0.        , 0.2       , 0.2236068 , 0.        ,\n",
              "        0.        , 0.        , 0.4       ],\n",
              "       [0.47434165, 0.2       , 0.        , 0.2236068 , 0.        ,\n",
              "        0.25819889, 0.        , 0.2       ],\n",
              "       [0.35355339, 0.2236068 , 0.2236068 , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.2236068 ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.20412415, 0.        , 0.25819889, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.25819889],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.47434165, 0.4       , 0.2       , 0.2236068 , 0.        ,\n",
              "        0.25819889, 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtm5zacrQqyO"
      },
      "source": [
        "# Função para sumarizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTAEqoIVQtsk"
      },
      "source": [
        "def sumarizar(texto, quantidade_sentencas):\r\n",
        "  sentencas_originais = [sentenca for sentenca in nltk.sent_tokenize(texto)]\r\n",
        "  sentencas_formatadas = [preprocessamento(sentenca_original) for sentenca_original in sentencas_originais]\r\n",
        "  matriz_similaridade = calcula_matriz_similaridade(sentencas_formatadas)\r\n",
        "  #print(matriz_similaridade)\r\n",
        "  grafo_similaridade = nx.from_numpy_array(matriz_similaridade)\r\n",
        "  #print(grafo_similaridade.nodes)\r\n",
        "  #print(grafo_similaridade.edges)\r\n",
        "  notas = nx.pagerank(grafo_similaridade)\r\n",
        "  #print(notas)\r\n",
        "  notas_ordenadas = sorted(((notas[i], nota) for i, nota in enumerate(sentencas_originais)), reverse=True)\r\n",
        "  #print(notas_ordenadas)\r\n",
        "  melhores_sentencas = []\r\n",
        "  for i in range(quantidade_sentencas):\r\n",
        "    melhores_sentencas.append(notas_ordenadas[i][1])\r\n",
        "  return sentencas_originais, melhores_sentencas, notas_ordenadas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9qp7oa_RD0M"
      },
      "source": [
        "sentencas_originais, melhores_sentencas, notas_sentencas = sumarizar(texto_original, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F72g1YHcT8W7",
        "outputId": "e85bf7d7-3dc7-4325-d9c4-e5645ba73d4c"
      },
      "source": [
        "sentencas_originais"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' A inteligência artificial é a inteligência similar à humana máquinas.',\n",
              " 'Definem como o estudo de agente artificial com inteligência.',\n",
              " 'Ciência e engenharia de produzir máquinas com inteligência.',\n",
              " 'Resolver problemas e possuir inteligência.',\n",
              " 'Relacionada ao comportamento inteligente.',\n",
              " 'Construção de máquinas para raciocinar.',\n",
              " 'Aprender com os erros e acertos.',\n",
              " 'Inteligência artificial é raciocinar nas situações do cotidiano.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXYKXO5_UAAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e3333d-3e97-4d85-e4c1-1b3d9e3a7af2"
      },
      "source": [
        "melhores_sentencas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' A inteligência artificial é a inteligência similar à humana máquinas.',\n",
              " 'Inteligência artificial é raciocinar nas situações do cotidiano.',\n",
              " 'Ciência e engenharia de produzir máquinas com inteligência.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e24iMCxdUCZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "309e2792-12c1-4eea-a5a8-33840dd842df"
      },
      "source": [
        "notas_sentencas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.22820924040178,\n",
              "  ' A inteligência artificial é a inteligência similar à humana máquinas.'),\n",
              " (0.1839190802151221,\n",
              "  'Inteligência artificial é raciocinar nas situações do cotidiano.'),\n",
              " (0.1633191450783496,\n",
              "  'Ciência e engenharia de produzir máquinas com inteligência.'),\n",
              " (0.15437170333277758,\n",
              "  'Definem como o estudo de agente artificial com inteligência.'),\n",
              " (0.12639273963873285, 'Resolver problemas e possuir inteligência.'),\n",
              " (0.0961690356396478, 'Construção de máquinas para raciocinar.'),\n",
              " (0.023809527846794958, 'Relacionada ao comportamento inteligente.'),\n",
              " (0.023809527846794958, 'Aprender com os erros e acertos.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UVNDSHGG5MK"
      },
      "source": [
        "# Visualização do resumo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlDT6tQHG9UY"
      },
      "source": [
        "def visualiza_resumo(titulo, lista_sentencas, melhores_sentencas):\r\n",
        "  texto = ''\r\n",
        "  display(HTML(f'<h1>Resumo do texto - {titulo}</h1>'))\r\n",
        "  for sentenca in lista_sentencas:\r\n",
        "    #texto += sentenca\r\n",
        "    if sentenca in melhores_sentencas:\r\n",
        "      texto += str(sentenca).replace(sentenca, f\"<mark>{sentenca}</mark>\") + \" \"\r\n",
        "    else:\r\n",
        "      texto += sentenca + \" \"\r\n",
        "  display(HTML(f\"\"\"{texto}\"\"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "HTxPiL7lH8dY",
        "outputId": "b0282c88-0da4-4d0b-dc09-f820c3a2cfb9"
      },
      "source": [
        "visualiza_resumo('Teste', sentencas_originais, melhores_sentencas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h1>Resumo do texto - Teste</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<mark> A inteligência artificial é a inteligência similar à humana máquinas.</mark> Definem como o estudo de agente artificial com inteligência. <mark>Ciência e engenharia de produzir máquinas com inteligência.</mark> Resolver problemas e possuir inteligência. Relacionada ao comportamento inteligente. Construção de máquinas para raciocinar. Aprender com os erros e acertos. <mark>Inteligência artificial é raciocinar nas situações do cotidiano.</mark> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13zDzoNJIfHI"
      },
      "source": [
        "# Extração de texto da internet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix1kip0TIitg",
        "outputId": "33cf0000-af70-4dfb-e0fa-e66e076cdc34"
      },
      "source": [
        "!pip install goose3 # para extrair textos da internet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting goose3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/0e/5d049211226268ebce83ae5c8c4f578af0f5f120b24de9542485efcfeda2/goose3-3.1.6-py3-none-any.whl (86kB)\n",
            "\r\u001b[K     |███▉                            | 10kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 20kB 20.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 30kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 71kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 81kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from goose3) (7.0.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from goose3) (0.42.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from goose3) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from goose3) (2.23.0)\n",
            "Collecting cssselect\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from goose3) (4.6.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from goose3) (3.2.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from goose3) (4.2.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->goose3) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->goose3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->goose3) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->goose3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->goose3) (2.10)\n",
            "Installing collected packages: cssselect, goose3\n",
            "Successfully installed cssselect-1.1.0 goose3-3.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9vJGf_GIq6Q"
      },
      "source": [
        "from goose3 import Goose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN7n_gPNIw1Y"
      },
      "source": [
        "g = Goose()\r\n",
        "url = 'https://iaexpert.academy/2020/11/09/ia-preve-resultado-das-eleicoes-americanas/'\r\n",
        "#url = 'https://cidadeemnumeros.com.br/2020/12/15/mp-instaura-inquerito-civil-sobre-escola-em-sao-caetano-do-sul/'\r\n",
        "artigo = g.extract(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "HAr9MOvAI7SA",
        "outputId": "47f586ec-24ca-4f9e-99bf-d01e20854e7d"
      },
      "source": [
        "artigo.cleaned_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.\\n\\nO modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais. O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito. No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.\\n\\nO Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado. Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores. O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento. O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana. A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual. O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la. Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho. Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado. Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.\\n\\nQuando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem. Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.\\n\\nParece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxbz6QXHI9ww"
      },
      "source": [
        "sentencas_originais, melhores_sentencas, notas_sentencas = sumarizar(artigo.cleaned_text, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgdJwd4CJnUY",
        "outputId": "9838f436-ddef-480e-beff-fdb8b6c48a09"
      },
      "source": [
        "sentencas_originais"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton.',\n",
              " 'Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos.',\n",
              " 'Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados.',\n",
              " 'Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.',\n",
              " 'O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.',\n",
              " 'O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito.',\n",
              " 'No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.',\n",
              " 'O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado.',\n",
              " 'Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.',\n",
              " 'O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento.',\n",
              " 'O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana.',\n",
              " 'A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.',\n",
              " 'O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la.',\n",
              " 'Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.',\n",
              " 'Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado.',\n",
              " 'Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.',\n",
              " 'Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.',\n",
              " 'Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.',\n",
              " 'Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaxT9KVcJqIH",
        "outputId": "b5ddd54a-4925-4639-a049-69159ebc0bf5"
      },
      "source": [
        "melhores_sentencas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.',\n",
              " 'Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.',\n",
              " 'No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.',\n",
              " 'Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.',\n",
              " 'O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWHnKiVbJslZ",
        "outputId": "c13a2560-94df-4de7-919c-7d4d3696d150"
      },
      "source": [
        "notas_sentencas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.10099691917637997,\n",
              "  'Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.'),\n",
              " (0.08211890797647801,\n",
              "  'Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.'),\n",
              " (0.07547555812522563,\n",
              "  'No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.'),\n",
              " (0.07334834938839217,\n",
              "  'Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.'),\n",
              " (0.07097153031645245,\n",
              "  'O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.'),\n",
              " (0.07084200739094762,\n",
              "  'Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.'),\n",
              " (0.06997085578620142,\n",
              "  'A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.'),\n",
              " (0.06460773577131418,\n",
              "  'O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado.'),\n",
              " (0.056608153943721165,\n",
              "  'Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados.'),\n",
              " (0.0560498118910006,\n",
              "  'Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton.'),\n",
              " (0.045097656441524255,\n",
              "  'Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.'),\n",
              " (0.045090727667958526,\n",
              "  'O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento.'),\n",
              " (0.038309483002189865,\n",
              "  'O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana.'),\n",
              " (0.036995456669427815,\n",
              "  'Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado.'),\n",
              " (0.032683122214555355,\n",
              "  'O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la.'),\n",
              " (0.026418607773050686,\n",
              "  'Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.'),\n",
              " (0.024338820575634898,\n",
              "  'O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito.'),\n",
              " (0.02181183307962798,\n",
              "  'Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.'),\n",
              " (0.00826446280991742,\n",
              "  'Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "CUHfAhpiJzW_",
        "outputId": "12d6c1fb-ce9f-483f-8604-750e5c538aa7"
      },
      "source": [
        "visualiza_resumo('Teste', sentencas_originais, melhores_sentencas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h1>Resumo do texto - Teste</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora. <mark>O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.</mark> O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito. <mark>No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.</mark> O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado. <mark>Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.</mark> O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento. O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana. A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual. O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la. <mark>Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.</mark> Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado. Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores. <mark>Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.</mark> Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito. Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas. "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zheRjanxMVs-"
      },
      "source": [
        "# Solução para o exercício - lematização\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n95_r-guMerQ"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE3gjL8sMaR3",
        "outputId": "92c57761-cf7b-4b2f-ed56-37ec85694066"
      },
      "source": [
        "!python -m spacy download pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pt_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2MB 1.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (51.1.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.5-cp36-none-any.whl size=21186283 sha256=90c235ddc26e8929da1a0a4cb9ea92153c6ea3554a381c6d4232dfda1e4729a6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cxphupit/wheels/ea/94/74/ec9be8418e9231b471be5dc7e1b45dd670019a376a6b5bc1c0\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPnSWq57Mq_n",
        "outputId": "92ea23a8-11f0-42ad-8bc6-f1825436b0d7"
      },
      "source": [
        "pln = spacy.load('pt')\r\n",
        "pln"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.pt.Portuguese at 0x7f3fa4a76588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SEVHKk1MzeP"
      },
      "source": [
        "def preprocessamento_lematizacao(texto):\r\n",
        "  texto = texto.lower()\r\n",
        "  texto = re.sub(r\" +\", ' ', texto)\r\n",
        "\r\n",
        "  documento = pln(texto)\r\n",
        "  tokens = []\r\n",
        "  for token in documento:\r\n",
        "    tokens.append(token.lemma_)\r\n",
        "\r\n",
        "  tokens = [palavra for palavra in tokens if palavra not in stopwords and palavra not in string.punctuation]\r\n",
        "  texto_formatado = ' '.join([str(elemento) for elemento in tokens if not elemento.isdigit()])\r\n",
        "\r\n",
        "  return texto_formatado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYk38RSDNxO6"
      },
      "source": [
        "def sumarizar_lematizacao(texto, quantidade_sentencas):\r\n",
        "  sentencas_originais = [sentenca for sentenca in nltk.sent_tokenize(texto)]\r\n",
        "  sentencas_formatadas = [preprocessamento_lematizacao(sentenca_original) for sentenca_original in sentencas_originais]\r\n",
        "  matriz_similaridade = calcula_matriz_similaridade(sentencas_formatadas)\r\n",
        "  grafo_similaridade = nx.from_numpy_array(matriz_similaridade)\r\n",
        "  notas = nx.pagerank(grafo_similaridade)\r\n",
        "  notas_ordenadas = sorted(((notas[i], nota) for i, nota in enumerate(sentencas_originais)), reverse= True)\r\n",
        "  melhores_sentencas = []\r\n",
        "  for i in range(quantidade_sentencas):\r\n",
        "    melhores_sentencas.append(notas_ordenadas[i][1])\r\n",
        "\r\n",
        "  return sentencas_originais, melhores_sentencas, notas_ordenadas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "4HEb1CXaKMNp",
        "outputId": "8195211f-f6cd-4260-be7f-498e68221f41"
      },
      "source": [
        "artigo.cleaned_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.\\n\\nO modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais. O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito. No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.\\n\\nO Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado. Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores. O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento. O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana. A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual. O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la. Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho. Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado. Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.\\n\\nQuando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem. Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.\\n\\nParece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UxnInACCKPx4",
        "outputId": "692d6736-39da-4281-f4b3-7f6e54c4fcef"
      },
      "source": [
        "sentencas_originais, melhores_sentencas, _ = sumarizar(artigo.cleaned_text, 5)\r\n",
        "visualiza_resumo(artigo.title, sentencas_originais, melhores_sentencas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h1>Resumo do texto - IA prevê resultado das eleições americanas – IA Expert</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora. <mark>O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.</mark> O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito. <mark>No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.</mark> O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado. <mark>Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.</mark> O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento. O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana. A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual. O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la. <mark>Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.</mark> Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado. Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores. <mark>Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.</mark> Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito. Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas. "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "5odIk0emM-nP",
        "outputId": "33894d5e-23a4-41d8-d390-448b93dbf6ad"
      },
      "source": [
        "sentencas_originais, melhores_sentencas, _ = sumarizar_lematizacao(artigo.cleaned_text, 5)\r\n",
        "visualiza_resumo(artigo.title, sentencas_originais, melhores_sentencas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h1>Resumo do texto - IA prevê resultado das eleições americanas – IA Expert</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora. O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais. O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito. No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden. O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado. Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores. O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento. O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana. <mark>A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.</mark> <mark>O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la.</mark> Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho. <mark>Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado.</mark> Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores. <mark>Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.</mark> Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito. <mark>Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.</mark> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}