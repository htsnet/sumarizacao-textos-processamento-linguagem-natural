{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Udemy Sumarizacao de Textos com Processamento de Linguagem Natural",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNmpQiBWGv/akP3wQmUPjG7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/htsnet/sumarizacao-textos-processamento-linguagem-natural/blob/main/Udemy_Sumarizacao_de_Textos_com_Processamento_de_Linguagem_Natural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-xE2oSEE55B"
      },
      "source": [
        "# Sumarização de Textos com processamento de linguagem natural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVTJlRxlFCZI"
      },
      "source": [
        "# Pré-processamento do texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0joB99hEmfo",
        "outputId": "ce65ae52-a1c1-4717-a69e-37c08ee620a6"
      },
      "source": [
        "import re\r\n",
        "import nltk\r\n",
        "import string # pacote para ter pontuação e outros\r\n",
        "nltk.download('punkt') #pacote para tokenizar\r\n",
        "nltk.download('stopwords') #pacote das stop words\r\n",
        "import heapq # pacote para buscar maiores valores em um dicionário\r\n",
        "from IPython.core.display import HTML\r\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkcaFtigHoYR"
      },
      "source": [
        "texto_original = \"\"\"\r\n",
        "        A inteligência artificial é a inteligência similar à humana. Definem como\r\n",
        "        o estudo de agente artificial com inteligência. Ciência e engenharia de\r\n",
        "        produzir máquinas com inteligência. Resolver problemas e possuir\r\n",
        "        inteligência. Relacionada ao comportamento inteligente. Construção de\r\n",
        "        máquinas para raciocinar. Aprender com os erros e acertos. Inteligência\r\n",
        "        artificial é raciocinar nas situações do cotidiano.\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "MQq3cPQuIJRU",
        "outputId": "dbc753d5-fefc-4e6f-b4ff-c18259a6482e"
      },
      "source": [
        "texto_original"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n        A inteligência artificial é a inteligência similar à humana. Definem como\\n        o estudo de agente artificial com inteligência. Ciência e engenharia de\\n        produzir máquinas com inteligência. Resolver problemas e possuir\\n        inteligência. Relacionada ao comportamento inteligente. Construção de\\n        máquinas para raciocinar. Aprender com os erros e acertos. Inteligência\\n        artificial é raciocinar nas situações do cotidiano.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RahuTNoiISfe"
      },
      "source": [
        "#expressão regular para tirar um ou mais espaços sobrando e quebra de linha\r\n",
        "texto_original = re.sub(r'\\s+', ' ', texto_original.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "ekG1EhC1JD3S",
        "outputId": "835857d6-c228-4ae2-cf4a-a2f259669ae4"
      },
      "source": [
        "texto_original"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A inteligência artificial é a inteligência similar à humana. Definem como o estudo de agente artificial com inteligência. Ciência e engenharia de produzir máquinas com inteligência. Resolver problemas e possuir inteligência. Relacionada ao comportamento inteligente. Construção de máquinas para raciocinar. Aprender com os erros e acertos. Inteligência artificial é raciocinar nas situações do cotidiano.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvQxoSJ9LdLo",
        "outputId": "75415000-59cd-4b8f-f776-baa389e1a77f"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('portuguese')\r\n",
        "print(stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TouJ1xHHLwc3",
        "outputId": "2496c19b-3774-4c34-cc4b-ae8fe6bd2c3d"
      },
      "source": [
        "len(stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UQosgVdPMRRt",
        "outputId": "2dfc1b04-951e-42f7-c61e-d770a4047e1f"
      },
      "source": [
        "string.punctuation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_6qXE8pOUCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a87bc79-3b41-402b-c494-0b6b7062e20b"
      },
      "source": [
        "# usando o pacote spaCy\r\n",
        "!python -m spacy download pt\r\n",
        "pln = spacy.load('pt')\r\n",
        "\r\n",
        "def preprocessamento(texto):\r\n",
        "  texto_formatado = texto.lower()\r\n",
        "  tokens = []\r\n",
        "  # usando o pacote NLTK\r\n",
        "  # for token in nltk.word_tokenize(texto_formatado):\r\n",
        "  #   tokens.append(token)\r\n",
        "\r\n",
        "  # usando o spaCy\r\n",
        "  for token in pln(texto_formatado):\r\n",
        "    tokens.append(token.lemma_)\r\n",
        "  tokens = [palavra for palavra in tokens if palavra not in stopwords and palavra not in string.punctuation ] \r\n",
        "  texto_formatado = ' '.join([str(elemento) for elemento in tokens if not elemento.isdigit()])  # remove valores numéricos\r\n",
        "  return texto_formatado"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pt_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (51.1.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.5-cp36-none-any.whl size=21186283 sha256=c54f5c4f49e657903d146d25cb100e9c972dec4b9a99e1d94fcbe5bd0c77210e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-62i_fo5p/wheels/ea/94/74/ec9be8418e9231b471be5dc7e1b45dd670019a376a6b5bc1c0\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "IeO-vHCdOoIr",
        "outputId": "5e92b430-8be4-4f64-e603-48914d66f903"
      },
      "source": [
        "texto_formatado = preprocessamento(texto_original)\r\n",
        "texto_formatado"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'inteligência artificial ser inteligência similar humano definir comer estudar agente artificial inteligência ciência engenhar produzir máquina inteligência resolver problema possuir inteligência relacionar comportamento inteligente construção máquina parir raciocinar aprender erro acerto inteligência artificial ser raciocinar situação cotidiano'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "PgIgktDhY7Eo",
        "outputId": "7a6abca4-610c-4349-bdbf-46ef3464d614"
      },
      "source": [
        "texto_original"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A inteligência artificial é a inteligência similar à humana. Definem como o estudo de agente artificial com inteligência. Ciência e engenharia de produzir máquinas com inteligência. Resolver problemas e possuir inteligência. Relacionada ao comportamento inteligente. Construção de máquinas para raciocinar. Aprender com os erros e acertos. Inteligência artificial é raciocinar nas situações do cotidiano.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnOS8Ki1NMTg"
      },
      "source": [
        "# Frequência das Palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ewcf9rXINRdv",
        "outputId": "ddcd66cd-92f3-4a8b-ec31-d40c8e4d9e6c"
      },
      "source": [
        "frequencia_palavras = nltk.FreqDist(nltk.word_tokenize(texto_formatado))\r\n",
        "frequencia_palavras # está em formato de dicionário: chave + valor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'acerto': 1,\n",
              "          'agente': 1,\n",
              "          'aprender': 1,\n",
              "          'artificial': 3,\n",
              "          'ciência': 1,\n",
              "          'comer': 1,\n",
              "          'comportamento': 1,\n",
              "          'construção': 1,\n",
              "          'cotidiano': 1,\n",
              "          'definir': 1,\n",
              "          'engenhar': 1,\n",
              "          'erro': 1,\n",
              "          'estudar': 1,\n",
              "          'humano': 1,\n",
              "          'inteligente': 1,\n",
              "          'inteligência': 6,\n",
              "          'máquina': 2,\n",
              "          'parir': 1,\n",
              "          'possuir': 1,\n",
              "          'problema': 1,\n",
              "          'produzir': 1,\n",
              "          'raciocinar': 2,\n",
              "          'relacionar': 1,\n",
              "          'resolver': 1,\n",
              "          'ser': 2,\n",
              "          'similar': 1,\n",
              "          'situação': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_Dzrv8LNx4c",
        "outputId": "97ba57c9-921e-4a5b-8e03-e27c40cc663a"
      },
      "source": [
        "frequencia_palavras['máquinas'] # acessando por chave do dicionário"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmMwwmrhOANc",
        "outputId": "570195a6-c383-4454-e958-0d84144088fe"
      },
      "source": [
        "# verificando as chaves no dicionário\r\n",
        "frequencia_palavras.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['inteligência', 'artificial', 'ser', 'similar', 'humano', 'definir', 'comer', 'estudar', 'agente', 'ciência', 'engenhar', 'produzir', 'máquina', 'resolver', 'problema', 'possuir', 'relacionar', 'comportamento', 'inteligente', 'construção', 'parir', 'raciocinar', 'aprender', 'erro', 'acerto', 'situação', 'cotidiano'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr5CJ-BbOZNc",
        "outputId": "a6dc5e4b-ece1-4d46-e493-996b8b77c585"
      },
      "source": [
        "frequencia_maxima = max(frequencia_palavras.values())\r\n",
        "frequencia_maxima"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aauu-Kp1Oh8U"
      },
      "source": [
        "for palavra in frequencia_palavras.keys():\r\n",
        "  frequencia_palavras[palavra] = (frequencia_palavras[palavra] / frequencia_maxima)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTqVESiAO1o8",
        "outputId": "6fb07588-ead6-49a6-fb54-ea9846010866"
      },
      "source": [
        "frequencia_palavras # vendo agora o valor proporcional das palavras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'acerto': 0.16666666666666666,\n",
              "          'agente': 0.16666666666666666,\n",
              "          'aprender': 0.16666666666666666,\n",
              "          'artificial': 0.5,\n",
              "          'ciência': 0.16666666666666666,\n",
              "          'comer': 0.16666666666666666,\n",
              "          'comportamento': 0.16666666666666666,\n",
              "          'construção': 0.16666666666666666,\n",
              "          'cotidiano': 0.16666666666666666,\n",
              "          'definir': 0.16666666666666666,\n",
              "          'engenhar': 0.16666666666666666,\n",
              "          'erro': 0.16666666666666666,\n",
              "          'estudar': 0.16666666666666666,\n",
              "          'humano': 0.16666666666666666,\n",
              "          'inteligente': 0.16666666666666666,\n",
              "          'inteligência': 1.0,\n",
              "          'máquina': 0.3333333333333333,\n",
              "          'parir': 0.16666666666666666,\n",
              "          'possuir': 0.16666666666666666,\n",
              "          'problema': 0.16666666666666666,\n",
              "          'produzir': 0.16666666666666666,\n",
              "          'raciocinar': 0.3333333333333333,\n",
              "          'relacionar': 0.16666666666666666,\n",
              "          'resolver': 0.16666666666666666,\n",
              "          'ser': 0.3333333333333333,\n",
              "          'similar': 0.16666666666666666,\n",
              "          'situação': 0.16666666666666666})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xlBzqzoPBzf"
      },
      "source": [
        "# Tokenização das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drJWUoSJPFcM",
        "outputId": "60c76766-7f36-4bc6-f952-3c273456a5e5"
      },
      "source": [
        "# entendendo a divisão por sentenças\r\n",
        "texto_apoio = 'o dr. joão foi para casa. Ele chegou cedo.' # aqui existem 2 pontos, sendo que o primeiro não é final de frase\r\n",
        "print(texto_apoio.split('.')) # fazendo este split a primeira sentença está errada"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['o dr', ' joão foi para casa', ' Ele chegou cedo', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Euxe-j1hP72k",
        "outputId": "98ba605d-cc89-410e-da40-0b9e3f5db5f8"
      },
      "source": [
        "print(nltk.sent_tokenize(texto_apoio)) # usando esta biblioteca as sentenças foram corretamente separadas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['o dr. joão foi para casa.', 'Ele chegou cedo.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZxUpocsQQTc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7121906-bf6b-48d4-84b4-a27fdec11f6b"
      },
      "source": [
        "lista_sentencas = nltk.sent_tokenize(texto_original) # aqui está usando o texto original por causa dos pontos\r\n",
        "lista_sentencas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A inteligência artificial é a inteligência similar à humana.',\n",
              " 'Definem como o estudo de agente artificial com inteligência.',\n",
              " 'Ciência e engenharia de produzir máquinas com inteligência.',\n",
              " 'Resolver problemas e possuir inteligência.',\n",
              " 'Relacionada ao comportamento inteligente.',\n",
              " 'Construção de máquinas para raciocinar.',\n",
              " 'Aprender com os erros e acertos.',\n",
              " 'Inteligência artificial é raciocinar nas situações do cotidiano.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1PnwyI1QoO7"
      },
      "source": [
        "# Geração do resumo (nota para as sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZWSpS5wQr_q"
      },
      "source": [
        "nota_sentencas = {}\r\n",
        "for sentenca in lista_sentencas:\r\n",
        "  #print(sentenca)\r\n",
        "  for palavra in nltk.word_tokenize(sentenca.lower()):  # atenção para deixar tudo minúsculo para não dar erro na localziação das palavras\r\n",
        "    #print(palavra)\r\n",
        "    if palavra in frequencia_palavras.keys():\r\n",
        "      if sentenca not in nota_sentencas.keys():\r\n",
        "        nota_sentencas[sentenca] = frequencia_palavras[palavra]\r\n",
        "      else:\r\n",
        "        nota_sentencas[sentenca] += frequencia_palavras[palavra]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8eUpgnBT_pr",
        "outputId": "615aec17-282b-478a-f82e-4cf2e9e528c9"
      },
      "source": [
        "nota_sentencas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A inteligência artificial é a inteligência similar à humana.': 2.6666666666666665,\n",
              " 'Aprender com os erros e acertos.': 0.16666666666666666,\n",
              " 'Ciência e engenharia de produzir máquinas com inteligência.': 1.3333333333333333,\n",
              " 'Construção de máquinas para raciocinar.': 0.5,\n",
              " 'Definem como o estudo de agente artificial com inteligência.': 1.6666666666666665,\n",
              " 'Inteligência artificial é raciocinar nas situações do cotidiano.': 2.0,\n",
              " 'Relacionada ao comportamento inteligente.': 0.3333333333333333,\n",
              " 'Resolver problemas e possuir inteligência.': 1.3333333333333333}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I27M4gGFUQDz",
        "outputId": "c6b0294c-390f-4cc5-a2ac-842ca3b371cc"
      },
      "source": [
        "melhores_sentencas = heapq.nlargest(3, nota_sentencas, key=nota_sentencas.get)\r\n",
        "melhores_sentencas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A inteligência artificial é a inteligência similar à humana.',\n",
              " 'Inteligência artificial é raciocinar nas situações do cotidiano.',\n",
              " 'Definem como o estudo de agente artificial com inteligência.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ksku1zYU9T5",
        "outputId": "6017a517-07fc-4909-84f0-a6cdd1bc7e57"
      },
      "source": [
        "resumo = ' '.join(melhores_sentencas)\r\n",
        "resumo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A inteligência artificial é a inteligência similar à humana. Inteligência artificial é raciocinar nas situações do cotidiano. Definem como o estudo de agente artificial com inteligência.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMDb-b9gU8UM"
      },
      "source": [
        "# Visualização do resumo como HTML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "hf_xhaYgU_ch",
        "outputId": "971b28a7-a930-48a0-dfcc-f5d45eb6c62d"
      },
      "source": [
        "texto = ''\r\n",
        "display(HTML(f'<h1>Resumo do texto</h1>'))\r\n",
        "for sentenca in lista_sentencas:\r\n",
        "  #texto += sentenca\r\n",
        "  if sentenca in melhores_sentencas:\r\n",
        "    texto += str(sentenca).replace(sentenca, f\"<mark>{sentenca}</mark>\") + \" \"\r\n",
        "  else:\r\n",
        "    texto += sentenca + \" \"\r\n",
        "display(HTML(f\"\"\"{texto}\"\"\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h1>Resumo do texto</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<mark>A inteligência artificial é a inteligência similar à humana.</mark> <mark>Definem como o estudo de agente artificial com inteligência.</mark> Ciência e engenharia de produzir máquinas com inteligência. Resolver problemas e possuir inteligência. Relacionada ao comportamento inteligente. Construção de máquinas para raciocinar. Aprender com os erros e acertos. <mark>Inteligência artificial é raciocinar nas situações do cotidiano.</mark> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xJS7azWYFiZ"
      },
      "source": [
        "# Extração de texto da internet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRLbd7vwYIqh",
        "outputId": "43789a44-2d19-46da-f043-020a24697233"
      },
      "source": [
        "!pip install goose3 # para extrair textos da internet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting goose3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/0e/5d049211226268ebce83ae5c8c4f578af0f5f120b24de9542485efcfeda2/goose3-3.1.6-py3-none-any.whl (86kB)\n",
            "\r\u001b[K     |███▉                            | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 20kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 30kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 40kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from goose3) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from goose3) (4.6.3)\n",
            "Collecting cssselect\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from goose3) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from goose3) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from goose3) (2.23.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from goose3) (7.0.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from goose3) (0.42.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->goose3) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->goose3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->goose3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->goose3) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->goose3) (2.10)\n",
            "Installing collected packages: cssselect, goose3\n",
            "Successfully installed cssselect-1.1.0 goose3-3.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYwGx9GcYSAo"
      },
      "source": [
        "from goose3 import Goose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAS9vgzeYVWY"
      },
      "source": [
        "g = Goose()\r\n",
        "url = 'https://iaexpert.academy/2020/11/09/ia-preve-resultado-das-eleicoes-americanas/'\r\n",
        "#url = 'https://cidadeemnumeros.com.br/2020/12/15/mp-instaura-inquerito-civil-sobre-escola-em-sao-caetano-do-sul/'\r\n",
        "artigo = g.extract(url)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_NkmujWYybQ",
        "outputId": "61a8b750-51ca-40da-e625-1b02b944364f"
      },
      "source": [
        "artigo.infos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'authors': [],\n",
              " 'cleaned_text': 'Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.\\n\\nO modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais. O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito. No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.\\n\\nO Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado. Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores. O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento. O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana. A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual. O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la. Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho. Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado. Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.\\n\\nQuando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem. Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.\\n\\nParece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.',\n",
              " 'domain': 'iaexpert.academy',\n",
              " 'image': None,\n",
              " 'links': ['https://www.ccny.cuny.edu/profiles/hernan-makse',\n",
              "  'https://www.express.co.uk/news/science/1355192/artificial-intelligence-ai-news-twitter-us-election-2020-prediction-trump-biden-evg'],\n",
              " 'meta': {'canonical': 'https://iaexpert.academy/2020/11/09/ia-preve-resultado-das-eleicoes-americanas/',\n",
              "  'description': '',\n",
              "  'encoding': 'UTF-8',\n",
              "  'favicon': 'https://cdn.shortpixel.ai/spai/q_+ret_img/https://mk0iaexpertacadlbryk.kinstacdn.com/wp-content/uploads/2020/06/cropped-favicon-1-32x32.png',\n",
              "  'keywords': '',\n",
              "  'lang': 'pt'},\n",
              " 'movies': [],\n",
              " 'opengraph': {},\n",
              " 'publish_date': None,\n",
              " 'tags': ['inteligência artificial', 'eleições', 'Estados Unidos'],\n",
              " 'title': 'IA prevê resultado das eleições americanas – IA Expert Academy',\n",
              " 'tweets': []}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1Dnz0XvY8AY",
        "outputId": "b768fe43-52b7-47c8-ad8d-6ca1deccc1c4"
      },
      "source": [
        "artigo.title"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'IA prevê resultado das eleições americanas – IA Expert Academy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgfiW4cEZOuf",
        "outputId": "f3cc908e-2973-4b3d-e082-a4e9b96fa57f"
      },
      "source": [
        "artigo.cleaned_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.\\n\\nO modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais. O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito. No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.\\n\\nO Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado. Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores. O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento. O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana. A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual. O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la. Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho. Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado. Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.\\n\\nQuando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem. Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.\\n\\nParece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpQeE4uuZRca",
        "outputId": "98aef99c-b98c-4df3-ce22-c30fcf694896"
      },
      "source": [
        "len(artigo.cleaned_text) # quantidade de palavras do artigo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2638"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoTgjcBgZZiP",
        "outputId": "24e80c4c-2fdf-4352-932f-caad7e5e2187"
      },
      "source": [
        "artigo_original = artigo.cleaned_text\r\n",
        "artigo_formatado = preprocessamento(artigo_original)\r\n",
        "artigo_formatado"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'eleição presidencial americano maioria predição apontar parir vitória hillary clinton entretanto história mostrar resultar opor donald trump ser presidente último ano d vez estatístico reexaminar modelo parir aumentar grau confiabilidade resultar n tentativo otimização predição inteligência artificial certamente ficar ser \\n\\n modelar desenvolver pelar dr hernan makse físico estatístico universidade cidade novo york basear suar predição umar redar neural treinar parir processar sentimento expresso rede social algoritmo fazer análise cercar bilião tweets parir chegar umar estimativo resultar pleito dia eleição novembro modelar estar indicar vitória joe biden \\n\\n dr makse dizer trabalhar começar eleição ser testar novamente eleição argentino ano passar d vez modelar estar treinar cercar vezar dar eleição americano anterior trabalhar depender apenas coleta dar tratamento estatístico adequar parir levar consideração dois variável externo viés amostragem taxar comparecimento primeiro fator referir fato rede social necessariamente representar população americano participação rede social costumar ser maior cidade grande fato ter preferência candidato modelar dever ser corrigir parir levar consideração opinião pessoa ser ativa n ambientar virtual segundar fator dever não-obrigatoriedade votação estar unir ser umar pessoa ter suar preferência poder ser comparecer locar votação parir efetivá-la segundar dr makse integrar dois variável modelar ser partir importante trabalhar acreditar ser umar razão parir estimativo último eleição basear método tradicional coleta informação ter falhar suar equipar acompanhar tendência apresentar último eleição europa modelo estar revelar cada vez melhorar \\n\\n modelar ser usar parir predizer resultar eleição corrente usar dar bruto joe biden aparecer comer vencedor largo vantagem após aplicar mecanismo correção parir dois vieses identificar vantagem diminuir biden ainda ser indicar comer favorito \\n\\n parecer d vez algoritmo estar fato contribuir parir predição ser preciso'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QERHQMyOegSH",
        "outputId": "f71c5196-e284-4352-cccc-c26bfb087f03"
      },
      "source": [
        "len(artigo_formatado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2023"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOKMU35yeqQu"
      },
      "source": [
        "def sumarizar(texto, quantidade_sentencas):\r\n",
        "  texto_original = texto\r\n",
        "  texto_formatado = preprocessamento(texto_original)\r\n",
        "\r\n",
        "  frequencia_palavras = nltk.FreqDist(nltk.word_tokenize(texto_formatado))\r\n",
        "  frequencia_maxima = max(frequencia_palavras.values())\r\n",
        "  for palavra in frequencia_palavras.keys():\r\n",
        "    frequencia_palavras[palavra] = (frequencia_palavras[palavra] / frequencia_maxima)\r\n",
        "  lista_sentencas = nltk.sent_tokenize(texto_original)  \r\n",
        "\r\n",
        "  nota_sentencas = {}\r\n",
        "  for sentenca in lista_sentencas:\r\n",
        "    #print(sentenca)\r\n",
        "    for palavra in nltk.word_tokenize(sentenca.lower()):  # atenção para deixar tudo minúsculo para não dar erro na localziação das palavras\r\n",
        "      #print(palavra)\r\n",
        "      if palavra in frequencia_palavras.keys():\r\n",
        "        if sentenca not in nota_sentencas.keys():\r\n",
        "          nota_sentencas[sentenca] = frequencia_palavras[palavra]\r\n",
        "        else:\r\n",
        "          nota_sentencas[sentenca] += frequencia_palavras[palavra]\r\n",
        "\r\n",
        "  melhores_sentencas = heapq.nlargest(quantidade_sentencas, nota_sentencas, key=nota_sentencas.get)\r\n",
        "\r\n",
        "  return lista_sentencas, melhores_sentencas, frequencia_palavras, nota_sentencas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC8BisDTg13v"
      },
      "source": [
        "lista_sentencas, melhores_sentencas, frequencia_palavras, nota_sentencas = sumarizar(artigo_original, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2rBGiH1i5dV",
        "outputId": "c6462942-c798-420b-9d30-80d11fb13239"
      },
      "source": [
        "lista_sentencas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton.',\n",
              " 'Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos.',\n",
              " 'Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados.',\n",
              " 'Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.',\n",
              " 'O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.',\n",
              " 'O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito.',\n",
              " 'No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.',\n",
              " 'O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado.',\n",
              " 'Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.',\n",
              " 'O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento.',\n",
              " 'O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana.',\n",
              " 'A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.',\n",
              " 'O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la.',\n",
              " 'Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.',\n",
              " 'Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado.',\n",
              " 'Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.',\n",
              " 'Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.',\n",
              " 'Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.',\n",
              " 'Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYfwQmvPjjY0",
        "outputId": "d002ef3a-d61e-4fd7-b4f6-1dba23fb449e"
      },
      "source": [
        "melhores_sentencas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.',\n",
              " 'O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la.',\n",
              " 'Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado.',\n",
              " 'Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.',\n",
              " 'No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnJoyCdDyh__",
        "outputId": "f49b2b5f-ab43-4a70-e218-7f3ee9917e1b"
      },
      "source": [
        "frequencia_palavras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'acompanhar': 0.07692307692307693,\n",
              "          'acreditar': 0.07692307692307693,\n",
              "          'adequar': 0.07692307692307693,\n",
              "          'ainda': 0.07692307692307693,\n",
              "          'algoritmo': 0.15384615384615385,\n",
              "          'ambientar': 0.07692307692307693,\n",
              "          'americano': 0.23076923076923078,\n",
              "          'amostragem': 0.07692307692307693,\n",
              "          'ano': 0.15384615384615385,\n",
              "          'anterior': 0.07692307692307693,\n",
              "          'análise': 0.07692307692307693,\n",
              "          'aparecer': 0.07692307692307693,\n",
              "          'apenas': 0.07692307692307693,\n",
              "          'aplicar': 0.07692307692307693,\n",
              "          'apontar': 0.07692307692307693,\n",
              "          'apresentar': 0.07692307692307693,\n",
              "          'após': 0.07692307692307693,\n",
              "          'argentino': 0.07692307692307693,\n",
              "          'artificial': 0.07692307692307693,\n",
              "          'ativa': 0.07692307692307693,\n",
              "          'aumentar': 0.07692307692307693,\n",
              "          'basear': 0.15384615384615385,\n",
              "          'biden': 0.23076923076923078,\n",
              "          'bilião': 0.07692307692307693,\n",
              "          'bruto': 0.07692307692307693,\n",
              "          'cada': 0.07692307692307693,\n",
              "          'candidato': 0.07692307692307693,\n",
              "          'cercar': 0.15384615384615385,\n",
              "          'certamente': 0.07692307692307693,\n",
              "          'chegar': 0.07692307692307693,\n",
              "          'cidade': 0.15384615384615385,\n",
              "          'clinton': 0.07692307692307693,\n",
              "          'coleta': 0.15384615384615385,\n",
              "          'comer': 0.15384615384615385,\n",
              "          'começar': 0.07692307692307693,\n",
              "          'comparecer': 0.07692307692307693,\n",
              "          'comparecimento': 0.07692307692307693,\n",
              "          'confiabilidade': 0.07692307692307693,\n",
              "          'consideração': 0.15384615384615385,\n",
              "          'contribuir': 0.07692307692307693,\n",
              "          'corrente': 0.07692307692307693,\n",
              "          'correção': 0.07692307692307693,\n",
              "          'corrigir': 0.07692307692307693,\n",
              "          'costumar': 0.07692307692307693,\n",
              "          'd': 0.23076923076923078,\n",
              "          'dar': 0.23076923076923078,\n",
              "          'depender': 0.07692307692307693,\n",
              "          'desenvolver': 0.07692307692307693,\n",
              "          'dever': 0.15384615384615385,\n",
              "          'dia': 0.07692307692307693,\n",
              "          'diminuir': 0.07692307692307693,\n",
              "          'dizer': 0.07692307692307693,\n",
              "          'dois': 0.23076923076923078,\n",
              "          'donald': 0.07692307692307693,\n",
              "          'dr': 0.23076923076923078,\n",
              "          'efetivá-la': 0.07692307692307693,\n",
              "          'eleição': 0.6153846153846154,\n",
              "          'entretanto': 0.07692307692307693,\n",
              "          'equipar': 0.07692307692307693,\n",
              "          'estar': 0.38461538461538464,\n",
              "          'estatístico': 0.23076923076923078,\n",
              "          'estimativo': 0.15384615384615385,\n",
              "          'europa': 0.07692307692307693,\n",
              "          'expresso': 0.07692307692307693,\n",
              "          'externo': 0.07692307692307693,\n",
              "          'falhar': 0.07692307692307693,\n",
              "          'fato': 0.23076923076923078,\n",
              "          'fator': 0.15384615384615385,\n",
              "          'favorito': 0.07692307692307693,\n",
              "          'fazer': 0.07692307692307693,\n",
              "          'ficar': 0.07692307692307693,\n",
              "          'físico': 0.07692307692307693,\n",
              "          'grande': 0.07692307692307693,\n",
              "          'grau': 0.07692307692307693,\n",
              "          'hernan': 0.07692307692307693,\n",
              "          'hillary': 0.07692307692307693,\n",
              "          'história': 0.07692307692307693,\n",
              "          'identificar': 0.07692307692307693,\n",
              "          'importante': 0.07692307692307693,\n",
              "          'indicar': 0.15384615384615385,\n",
              "          'informação': 0.07692307692307693,\n",
              "          'integrar': 0.07692307692307693,\n",
              "          'inteligência': 0.07692307692307693,\n",
              "          'joe': 0.15384615384615385,\n",
              "          'largo': 0.07692307692307693,\n",
              "          'levar': 0.15384615384615385,\n",
              "          'locar': 0.07692307692307693,\n",
              "          'maior': 0.07692307692307693,\n",
              "          'maioria': 0.07692307692307693,\n",
              "          'makse': 0.23076923076923078,\n",
              "          'mecanismo': 0.07692307692307693,\n",
              "          'melhorar': 0.07692307692307693,\n",
              "          'modelar': 0.46153846153846156,\n",
              "          'modelo': 0.15384615384615385,\n",
              "          'mostrar': 0.07692307692307693,\n",
              "          'método': 0.07692307692307693,\n",
              "          'n': 0.15384615384615385,\n",
              "          'necessariamente': 0.07692307692307693,\n",
              "          'neural': 0.07692307692307693,\n",
              "          'novamente': 0.07692307692307693,\n",
              "          'novembro': 0.07692307692307693,\n",
              "          'novo': 0.07692307692307693,\n",
              "          'não-obrigatoriedade': 0.07692307692307693,\n",
              "          'opinião': 0.07692307692307693,\n",
              "          'opor': 0.07692307692307693,\n",
              "          'otimização': 0.07692307692307693,\n",
              "          'parecer': 0.07692307692307693,\n",
              "          'parir': 0.8461538461538461,\n",
              "          'participação': 0.07692307692307693,\n",
              "          'partir': 0.07692307692307693,\n",
              "          'passar': 0.07692307692307693,\n",
              "          'pelar': 0.07692307692307693,\n",
              "          'pessoa': 0.15384615384615385,\n",
              "          'pleito': 0.07692307692307693,\n",
              "          'poder': 0.07692307692307693,\n",
              "          'população': 0.07692307692307693,\n",
              "          'preciso': 0.07692307692307693,\n",
              "          'predizer': 0.07692307692307693,\n",
              "          'predição': 0.3076923076923077,\n",
              "          'preferência': 0.15384615384615385,\n",
              "          'presidencial': 0.07692307692307693,\n",
              "          'presidente': 0.07692307692307693,\n",
              "          'primeiro': 0.07692307692307693,\n",
              "          'processar': 0.07692307692307693,\n",
              "          'razão': 0.07692307692307693,\n",
              "          'redar': 0.07692307692307693,\n",
              "          'rede': 0.23076923076923078,\n",
              "          'reexaminar': 0.07692307692307693,\n",
              "          'referir': 0.07692307692307693,\n",
              "          'representar': 0.07692307692307693,\n",
              "          'resultar': 0.3076923076923077,\n",
              "          'revelar': 0.07692307692307693,\n",
              "          'segundar': 0.15384615384615385,\n",
              "          'sentimento': 0.07692307692307693,\n",
              "          'ser': 1.0,\n",
              "          'social': 0.23076923076923078,\n",
              "          'suar': 0.23076923076923078,\n",
              "          'taxar': 0.07692307692307693,\n",
              "          'tendência': 0.07692307692307693,\n",
              "          'tentativo': 0.07692307692307693,\n",
              "          'ter': 0.23076923076923078,\n",
              "          'testar': 0.07692307692307693,\n",
              "          'trabalhar': 0.23076923076923078,\n",
              "          'tradicional': 0.07692307692307693,\n",
              "          'tratamento': 0.07692307692307693,\n",
              "          'treinar': 0.15384615384615385,\n",
              "          'trump': 0.07692307692307693,\n",
              "          'tweets': 0.07692307692307693,\n",
              "          'umar': 0.3076923076923077,\n",
              "          'unir': 0.07692307692307693,\n",
              "          'universidade': 0.07692307692307693,\n",
              "          'usar': 0.15384615384615385,\n",
              "          'vantagem': 0.15384615384615385,\n",
              "          'variável': 0.15384615384615385,\n",
              "          'vencedor': 0.07692307692307693,\n",
              "          'vez': 0.3076923076923077,\n",
              "          'vezar': 0.07692307692307693,\n",
              "          'vieses': 0.07692307692307693,\n",
              "          'virtual': 0.07692307692307693,\n",
              "          'vitória': 0.15384615384615385,\n",
              "          'viés': 0.07692307692307693,\n",
              "          'votação': 0.15384615384615385,\n",
              "          'york': 0.07692307692307693,\n",
              "          'último': 0.23076923076923078})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjCDY8VMXKxn"
      },
      "source": [
        "def visualiza_resumo(titulo, lista_sentencas, melhores_sentencas):\r\n",
        "  texto = ''\r\n",
        "  display(HTML(f'<h1>Resumo do texto - {titulo}</h1>'))\r\n",
        "  for sentenca in lista_sentencas:\r\n",
        "    #texto += sentenca\r\n",
        "    if sentenca in melhores_sentencas:\r\n",
        "      texto += str(sentenca).replace(sentenca, f\"<mark>{sentenca}</mark>\") + \" \"\r\n",
        "    else:\r\n",
        "      texto += sentenca + \" \"\r\n",
        "  display(HTML(f\"\"\"{texto}\"\"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-tWvABiXoTo",
        "outputId": "07181f85-3fee-4225-da63-37618655dd45"
      },
      "source": [
        "visualiza_resumo(\"Eleições\", lista_sentencas, melhores_sentencas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h1>Resumo do texto - Eleições</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora. O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais. O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito. <mark>No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.</mark> O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado. Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores. O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento. O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana. <mark>A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.</mark> <mark>O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la.</mark> Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho. <mark>Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado.</mark> Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores. <mark>Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.</mark> Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito. Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas. "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnzEG8FdemPH"
      },
      "source": [
        "# Sumarização de mais textos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6xj-4o7aNVJ"
      },
      "source": [
        "lista_artigos = ['https://iaexpert.academy/2020/11/06/ia-detecta-deep-fakes-produzidos-com-tecnicas-recentes/',\r\n",
        "                 'https://iaexpert.academy/2020/11/13/facebook-apresenta-novo-algoritmo-deteccao-fake-news/',\r\n",
        "                 'https://iaexpert.academy/2020/11/16/automl-aspectos-aplicacoes/']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27TBs93va3fQ",
        "outputId": "ae87022d-bccf-44a3-bdbe-9e05f815029e"
      },
      "source": [
        "for url in lista_artigos:\r\n",
        "  #print(url)\r\n",
        "  g = Goose()\r\n",
        "  artigo = g.extract(url)\r\n",
        "  lista_sentencas, melhores_sentencas, _, _ = sumarizar(artigo.cleaned_text, 5)\r\n",
        "  visualiza_resumo(artigo.title, lista_sentencas, melhores_sentencas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h1>Resumo do texto - IA detecta deep fakes produzidos com as técnicas mais recentes – IA Expert Academy</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<mark>No ano passado, pesquisadores da Universidade de Stanford publicaram um trabalho descrevendo uma tecnologia para sincronização de lábios que permitia que editores de vídeo pudessem alterar as palavras de quem está falando de forma quase imperceptível, o que permitia inserir ou remover palavras mesmo no meio de frases.</mark> <mark>A tecnologia tem aplicações benéficas, como durante a edição de filmes, onde não seria necessário refilmar sequências ou fazer malabarismos de montagem para que o resultado final ficasse de acordo com a vontade do diretor.</mark> <mark>Entretanto, ela também poderia ser utilizada com más intenções, como para produzir deep fakes com conteúdo desinformativo.</mark> Este ano, os mesmos pesquisadores apresentaram um novo trabalho capaz de detectar as alterações realizadas. <mark>Ele se baseia nas mesmas ideias desenvolvidas no trabalho anterior, que buscavam parear fonemas com o que eles chamaram de “visemas”, correspondentes à posição dos lábios durante a produção do fonema.</mark> Apesar de as edições produzidas terem passado despercebidas por avaliadores humanos, ainda assim alguns artefatos são inseridos, sobretudo em fonemas com visemas bem característicos, como aqueles das letras M, B e P. Nestes casos, os lábios devem se fechar de forma firme. Pequenas diferenças entre as representações reais e criadas destes visemas foram utilizadas para detectar as sessões editadas dos vídeos com o uso de uma rede neural convolucional. No trabalho, os cientistas avaliaram vários vídeos adulterados do ex-presidente Barack Obama. O algoritmo, treinado com instâncias deste dataset, conseguiu identificar os casos de deep fake com precisão superior a 90%. Quando avaliado em um dataset mais amplo contendo outras pessoas, a precisão foi de 81%. <mark>Os autores comentam que detecções de deep fake com manipulação espacial e temporal limitada, como as edições feitas para alterar sutilmente um discurso de forma a mudar sua interpretação, são particularmente difíceis de detectar.</mark> Em casos de alto risco, a avaliação pode ser feita por uma pessoa qualificada, mas num ambiente mais amplo, técnicas automáticas são necessárias. Neste sentido, seu trabalho é um avanço importante no combate às más práticas associadas a esta tecnologia, já que apresenta resultados promissores avaliando deep fakes criados com as técnicas mais recentes. "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h1>Resumo do texto - Facebook apresenta novo algoritmo para detecção de fake news – IA Expert Academy</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Já é de amplo reconhecimento que as redes sociais afetaram o panorama político nos países com eleições. Se por um lado, as plataformas permitem a disseminação de ideias e programas políticos, permitindo uma maior divulgação de candidatos menos populares, por outro, agentes mal-intencionados têm usado as redes para disseminar fake news e assim manipular as eleições em seu favor. Em função de todo este poder, nos últimos anos tem aumentado a pressão para que empresas como Facebook e Twitter tomem medidas de forma a amenizar os efeitos nocivos que suas plataformas podem ter. <mark>Em agosto deste ano, o Facebook apresentou na Conferência de Data Mining e Descoberta de Conhecimento (Conference on Knowledge Discovery and Data Mining – KDD) um trabalho detalhando um modelo implementado pela empresa para, como diz o título do artigo, “melhorar a integridade da rede social”.</mark> <mark>O modelo faz uso de uma nova abstração chamada de embeddings de interação temporal (Temporal Interaction EmbeddingS – TIES), que foi desenvolvida com o objetivo de reconhecer interações sociais “rebeldes” para que elas possam ser encaminhadas para tratamento individualizado.</mark> O modelo tem a estrutura de uma rede neural, treinado de forma supervisionada, e incorpora características estáticas e dinâmicas das chamadas entidades sociais. <mark>Isso quer dizer que, ao contrários dos métodos anteriores que focavam em apenas um desses aspectos – por exemplo, o histórico de postagem ou a lista de amigos das contas -, o novo algoritmo leva ambos em consideração, “desmontando” as interações em partes como quem esteve envolvido, e o que e onde aconteceu.</mark> <mark>Isso foi possível graças à evolução recente nos domínios de embeddings de grafos, usados para representar interações em uma rede, e de aprendizagem de comportamento sequencial profunda, capaz de classificar a intenção de um agente através da consistência de seu comportamento.</mark> O resultado é uma compreensão mais detalhada sobre a natureza da conta e das postagens, que permite um controle mais fino dos moderadores. No artigo, o Facebook demonstrou o uso da ferramenta na prevenção da disseminação de fake news e na detecção de contas falsas. A abordagem certamente tem suas limitações. <mark>Em primeiro lugar, por se tratar de um problema supervisionado, instâncias devem ser rotuladas por pessoal técnico antes do treinamento, e nem sempre é fácil classificar um comportamento como malicioso.</mark> Em segundo, a ferramenta apenas identifica situações suspeitas, mas o plano de ação continua sendo delegado a um moderador, dependendo de avaliações de natureza bastante subjetiva. Mas há de se reconhecer os esforços da empresa em assumir responsabilidade pelo uso indevido da sua plataforma. Além de controlar o fluxo de informações falsas, as empresas pretendem manter a confiança em suas plataformas, para garantir que o ambiente mantenha sua percepção como saudável, construtivo e convidativo aos usuários. "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h1>Resumo do texto - AutoML: aspectos e aplicações – IA Expert Academy</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Os algoritmos de machine learning são métodos numéricos implementados na forma de linguagem de programação, para que sejam processados por computadores. Estes métodos são formulados de forma que o algoritmo resolva um problema não através da sua modelagem matemática, que exigiria o conhecimento de uma equação específica que descreve o problema, mas sim através de um modelo mais genérico, capaz de aproximar a equação desconhecida, e que por um processo iterativo tende a convergir para uma solução. Seu grande sucesso se deve ao fato de que os computadores são ideais para implementar estas iterações, já que elas são blocos de operações matemáticas mais simples que se repetem até que a solução seja alcançada. Através das iterações, os algoritmos ajustam seus parâmetros internos de forma que o modelo seja capaz de reproduzir as respostas do problema a partir dos dados de entrada. É assim que os modelos de machine learning ganham a capacidade de fazer predições em novos dados. <mark>Apesar de o processo descrito acima ser automatizado, existem alguns parâmetros que, via de regra, não podem ser ajustados de maneira automática.</mark> <mark>Isto se deve principalmente ao fato de que não existe uma relação matemática precisa entre estes hiperparâmetros e o desempenho do modelo, para que eles possam ser ajustados computacionalmente na direção da melhor solução.</mark> <mark>Além disso, eles costumam ser independentes entre si, de forma que diferentes combinações de valores de hiperparâmetros produzem resultados sem relação entre si, e pode ser que a solução ideal resida num espaço bastante distante de outras soluções adequadas.</mark> <mark>Os hiperparâmetros, que incluem a escolha do modelo e seus ajustes específicos, costumam ser configurados manualmente pelo desenvolvedor, que só vai saber sua qualidade ao final do processo de treinamento, avaliando as métricas de desempenho.</mark> O sucesso em sua escolha vai depender do conhecimento que o desenvolvedor tem sobre os dados com que está trabalhando, sua experiência em utilizar e ajustar os diferentes algoritmos disponíveis, e ainda uma boa dose de sorte. Mais recentemente, surgiram algumas bibliotecas buscando automatizar esta etapa inerentemente exploratória do processo de desenvolvimento de algoritmos de machine learning. Elas funcionam basicamente testando diferentes valores de hiperparâmetros e suas combinações, orientados por alguma heurística que estabelece uma direção para esta busca, retornando o desempenho do modelo nestas diferentes situações. Se por um lado esta abordagem ignora a intuição do desenvolvedor na escolha dos hiperparâmetros a serem testados, por outro ela poupa tempo que o desenvolvedor gastaria escrevendo código, e agora pode dispender em outras tarefas. A bem da verdade, há vantagens e desvantagens na sua utilização, além de fases específicas de um projeto onde elas podem ser de grande utilidade. Quando um cientista de dados inicia um novo projeto, é essencial desenvolver rapidamente uma ideia sobre sua viabilidade, já que, em uma empresa, o principal objetivo deste profissional é entregar valor. Como a natureza dos dados começa geralmente desconhecida, usar ferramentas de machine learning automático nesta fase inicial ajuda a estabelecer uma ideia mínima sobre o custo de oportunidade do projeto. Os modelos gerados desta forma podem servir como baseline, estabelecendo o desempenho mínimo possível a partir do qual a empresa pode decidir se a ideia toda vale a pena, se é sensato investir mais tempo e recursos para tentar melhorar este panorama inicial. <mark>O AutoML nesta fase inicial também ajuda a definir um cenário geral a ser explorado.</mark> Digamos que a abordagem revele que os melhores modelos são de uma determinada família de métodos numéricos. Então, é possível que os processos de otimização seguintes sejam melhor sucedidos se continuarem a exploração neste sentido. Assim, o cientista de dados já pula uma fase longa do desenvolvimento, podendo focar sua atenção na compreensão das tarefas mais específicas que o método de AutoML não é capaz de realizar. Outra grande vantagem de recorrer a métodos de AutoML é quando a empresa está em transição para ser um negócio orientado por dados. Nesta fase, ela ainda pode estar reticente sobre desenvolver toda uma nova área, estabelecer toda uma nova cultura, e o AutoML fornece uma indicação para responder se é hora de tomar essa decisão. Em muitas situações, faz mais sentido reciclar um desenvolvedor interno da empresa para fazer este estudo inicial do que contratar um profissional específico, com conhecimento técnico suficiente, para obter a mesma resposta. Diante da possibilidade de otimizar modelos usando ferramentas automáticas, muitos se perguntam se ainda há espaço para os cientistas de dados que faziam este trabalho manualmente. Mas certamente há. O AutoML ainda é incapaz de incorporar conhecimento que não seja facilmente expresso em operações matemáticas simples; ele não faz, por exemplo, as etapas de feature engineering e análise causal, não resolve situações de data leakage, não considera como a escolha do modelo impacta a fase de produção do projeto, e não incorpora aspectos relacionados ao negócio. Pode ser que o AutoML encontre uma solução inviável em termos práticos. É papel do cientista de dados refinar seus resultados. De fato, a menor parte do tempo de um cientista de dados é gasta escrevendo código e desenvolvendo modelos; sua expertise está muito mais relacionada em como conectar o conhecimento oriundo dos dados com suas aplicações no mundo real. Ao invés de um concorrente, o AutoML é mais uma ferramenta que o cientista de dados dispõe, que automatiza uma parte mais braçal de seu trabalho para que ele possa se concentrar nas tarefas mais complexas. Alguns de seus pontos fortes disponíveis ao cientista de dados são: geração de baselines confiáveis e consistentes, aumento da reprodutibilidade e da robustez metodológica, disponibilidade de várias heurísticas de treinamento, e maior possibilidade de experimentação. A seguir apresentamos algumas das bibliotecas mais citadas atualmente. Fazendo uso da extensa coleção de métodos do Scikit-Learn, temos a Auto-Sklearn e a Hyperopt-Sklearn, que fazem uma busca no espaço de soluções usando otimização bayesiana. A TPOT se baseia em um pipeline que busca valores de hiperparâmetros usando uma abordagem baseada em árvore de decisão. A AutoKeras permite a otimização de redes neurais construídas usando o Keras. A H2O pesquisa os melhores parâmetros para modelos baseados em árvores de decisão e redes neurais. Via de regra, estas bibliotecas são extremamente fáceis de implementar. A ideia geral é fornecer os dados e alguns limitantes como o tempo disponível para rodar a otimização. Muito prático, não? Assim como várias tarefas de outras profissões vão sendo substituídas por métodos automatizados, algumas atribuições do cientista de dados também são passíveis de passar por esta transformação. Mas a ciência de dados tem muito a ganhar com o uso das ferramentas de AutoML, explorando seus pontos fortes e deixando os profissionais livres para trabalharem em seus pontos fracos. No final do dia, o AutoML é uma ferramenta poderosa disponível no arsenal do cientista de dados, mas ainda assim apenas uma ferramenta, que precisa de um operador para coordenar como esta pequena parte do trabalho vai integrar com o todo. "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}